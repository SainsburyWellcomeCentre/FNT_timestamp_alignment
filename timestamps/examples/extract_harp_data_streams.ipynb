{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and script to interface with recorded Harp Binaries\n",
    "\n",
    "**Inputs:**\n",
    "- Binary files in session folder saved in 'Behavior.harp', and 'SoundCard.harp' subdirectories.<br>\n",
    "\n",
    "**Key outputs**\n",
    "- **poke_events**: A Data Frame with all nose poke events recorded in ports 0 and 1, where the index (Time) gives the timestamp of poke events in port 0 (DIPort0) and 1 (DIport1). An event occurs every time DIPort0 or DIPort1 switch to true or false, (indicating a nose poke in or out respectively).\n",
    "- **photodiode_data**: A Series in which the index (Time) gives timestamps of an analogue signal (AnalogueInput0) sampled from a photodiode\n",
    "- **audio_events**: A data frame with all audio events which occur whenever a message is sent to the sound card to play an audio file, with the columns:  \n",
    "    - \"**Time**\", specifying the timestamp (in seconds) of the onset of each audio event. \n",
    "    - \"**PlaySoundOrFrequency**\",  specifying the index on which the audio file was set, where 14 indicates the audio cue for port 0, 10 indicates the audio cue for port 1 and 18 indicates an audio file for silence.  \n",
    "\n",
    "Note that there are no event \"onsets\" and \"offsets\" as with the poke events, but rather a continuous stream of events, with audio onsets indicated by the onset of silence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries and define data folder\n",
    "import harp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import timestamps.harp.utils as hu\n",
    "#==============================================================================\n",
    "\n",
    "# Choose example session to analyze\n",
    "animal_ID = 'FNT099'\n",
    "session_ID = '2024-05-13T11-03-59'\n",
    "\n",
    "# path raw data on Ceph\n",
    "raw_data_dir = \"W:\\\\projects\\\\FlexiVexi\\\\raw_data\" \n",
    "#==============================================================================\n",
    "\n",
    "# Create reader for behavior.\n",
    "bin_b_path = os.path.join(raw_data_dir, animal_ID, session_ID, \"Behavior.harp\")\n",
    "behavior_reader = harp.create_reader(bin_b_path)\n",
    "\n",
    "# Specify mapping from sound index to reward port (This shouldn't change unless \n",
    "# you reprogramme the soundcard!)\n",
    "soundIdx0 = 14\n",
    "soundIdx1 = 10\n",
    "soundOffIdx = 18\n",
    "\n",
    "# Output folder to save intermediate variables (Use session folder in raw data directory)\n",
    "session_output_folder = os.path.join(raw_data_dir, animal_ID, session_ID, \"harp_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all poke events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in harp binaries to get poke events data frame\n",
    "poke_events = hu.get_all_pokes(behavior_reader)\n",
    "poke_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse photodiode data**\n",
    "\n",
    "The photodiode signal clearly separates periods where nothing is happening from periods where either the dot is being projected, or the fail state is on (in which the arena lights turn on). However, the dot projection and fail states are not clearly distinguishable with a single threshold, since both states result in saturation of the photodiode. \n",
    "\n",
    "Workarounds for this will be explored in the ephys-postprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photodiode_data = hu.parse_photodiode_data(behavior_reader)\n",
    "\n",
    "# Plot first 100 seconds of raw photodiode data\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.xlim(photodiode_data.index[0], photodiode_data.index[0] + 100)\n",
    "plt.plot(photodiode_data, label = 'Photodiode Signal')\n",
    "plt.xlabel('Time (Harp timestamps)')\n",
    "plt.ylabel('AU')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Plot Raw Photodiode Signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all audio events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sound card binary data (register 32) and show resulting dataframe\n",
    "bin_sound_path = os.path.join(raw_data_dir, animal_ID, session_ID, \"SoundCard.harp\",\"SoundCard_32.bin\")\n",
    "\n",
    "# Read the harp sound card stream, for the timestamps and audio ID\n",
    "all_sounds = hu.get_all_sounds(bin_sound_path)\n",
    "\n",
    "# Show data frame\n",
    "all_sounds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
