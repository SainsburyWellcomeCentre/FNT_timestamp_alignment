{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and script to construct a data frame trials information from raw Bonsai outputs\n",
    "\n",
    "**Inputs:**\n",
    "- .csv files containing raw harp data\n",
    "    - poke_events.csv, containing timestamps of nose pokes to port 0 and port 1\n",
    "    - sound_events.csv, containing timestamps of sound events\n",
    "    - photodiode_data,\n",
    "- experimental-data.csv file in 'Experimental-data' subdirectory containing trial-level behavioural data output directory from Bonsai workflow.\n",
    "\n",
    "**Key outputs**\n",
    "- trials_df data frame containing a summary of behavioural events in each trial including harp timestamps for dot onset and offset, nose pokes, and audio onset and offset times within each trial. Note that this data set contains redundancy to double check consistency of trial information between this script and the Bonsai output. \n",
    "\n",
    "**Overview** \n",
    "1. Read r\n",
    "2. Align key behavioural events to trials in a pandas data frame in which each row represents one trial. \n",
    "3. Append harp data frame to behavioural summary data frame containing trial-level information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries and define data folder\n",
    "import harp\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#==============================================================================\n",
    "\n",
    "# Choose example session to analyze\n",
    "animal_ID = 'FNT099'\n",
    "session_ID = '2024-05-13T11-03-59'\n",
    "\n",
    "# path raw data on Ceph\n",
    "raw_data_dir = \"W:\\\\projects\\\\FlexiVexi\\\\raw_data\"\n",
    "#==============================================================================\n",
    "\n",
    "# Create reader for behavior.\n",
    "bin_b_path = os.path.join(raw_data_dir, animal_ID, session_ID, \"Behavior.harp\")\n",
    "behavior_reader = harp.create_reader(bin_b_path)\n",
    "\n",
    "# Specify mapping from sound index to reward port (This shouldn't change unless \n",
    "# you reprogramme the soundcard!)\n",
    "soundIdx0 = 14\n",
    "soundIdx1 = 10\n",
    "soundOffIdx = 18\n",
    "\n",
    "# Output folder to save intermediate variables (Use session folder in raw data directory)\n",
    "harp_data_dir = os.path.join(raw_data_dir, animal_ID, session_ID, \"harp_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Read in raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all poke events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in poke events .csv as a pandas dataframe\n",
    "poke_events_filename = animal_ID + '_' + session_ID + '_' + 'poke_events.csv'\n",
    "poke_events_filepath = os.path.join(harp_data_dir, poke_events_filename)\n",
    "poke_events = pd.read_csv(poke_events_filepath)\n",
    "poke_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse photodiode data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in photodiode data .csv as a Series\n",
    "photodiode_filename = animal_ID + '_' + session_ID + '_' + 'photodiode_data.csv'\n",
    "photodiode_filepath = os.path.join(harp_data_dir, photodiode_filename)\n",
    "photodiode_data = pd.read_csv(photodiode_filepath)\n",
    "\n",
    "# Set 'Time' as the index and extract 'AnalogInput0' as a Series\n",
    "photodiode_data = photodiode_data.set_index('Time')['AnalogInput0']\n",
    "\n",
    "photodiode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all audio events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in poke events .csv as a pandas dataframe\n",
    "sound_events_filename = animal_ID + '_' + session_ID + '_' + 'sound_events.csv'\n",
    "sound_events_filepath = os.path.join(harp_data_dir, sound_events_filename)\n",
    "sound_events = pd.read_csv(sound_events_filepath)\n",
    "sound_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Data frame with Bonsai-triggered event timestamps and trial logic**\n",
    "\n",
    "Note that this step is necessary for constructing trial information data frame downstream.\n",
    "\n",
    "We will also change transform the data frame into something that is more useful for analysis as follows:\n",
    "\n",
    "1. Append animal and session ID to trials_df\n",
    "\n",
    "2. Reparameterise TrialCompletionCode into a more useful format:\n",
    "    - CorrectTrial\n",
    "    - AbortTrial\n",
    "    - ChoicePort\n",
    "    - CorrectPort\n",
    "\n",
    "3. Rename 'DotOnsetTime' and 'DotOffsetTime' to 'DotOnsetTrigger' and 'DotOffsetTrigger' to distinguish the timestamp of the Bonsai trigger to project/offset the dot from the true onset/offset of the dot, which are extracted from the photodiode data downstream. This is necessary only as a common-sense check since our method of extracting dot onset/offset time from photodiode is not completely robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experimental_data(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively searches for the 'experimental-data.csv' file within the given root directory.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory to start the search from.\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the 'experimental-data.csv' file if found, otherwise None.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"experimental-data.csv\"):\n",
    "                return os.path.join(root, file)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reparameterise_TrialCompletionCode(trial_data):\n",
    "    \"\"\"\n",
    "    Parses the TrialCompletionCode into a more useful parameterization.\n",
    "\n",
    "    Parameters:\n",
    "    trial_data (pd.DataFrame): DataFrame containing trial data with the following columns:\n",
    "        - 'TrialCompletionCode' (str): Code indicating the outcome of the trial.\n",
    "        - 'AudioCueIdentity' (int): Identifier for the audio cue used in the trial.\n",
    "        - 'TrialNumber' (int): Identifier for the trial number.\n",
    "        - 'Animal_ID' (str): Identifier for the animal.\n",
    "        - 'Session_ID' (str): Identifier for the session.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The modified DataFrame with additional columns:\n",
    "        - 'CorrectTrial' (bool): Indicates if the trial was correct.\n",
    "        - 'AbortTrial' (int): Indicates the type of aborted trial (1 for nosepoke, -1 for dot offset, 0 otherwise).\n",
    "        - 'ChoicePort' (int): The chosen port ID for non-aborted trials.\n",
    "        - 'CorrectPort' (int): The correct port ID based on the audio cue identity.\n",
    "    \n",
    "    Example usage:\n",
    "    trial_data = reparameterise_TrialCompletionCode(trial_data)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract logical value for whether trial was correct\n",
    "    trial_data['CorrectTrial'] = trial_data['TrialCompletionCode'].apply(lambda x: x[:-1] == 'RewardedNosepoke')\n",
    "\n",
    "    # MAKE DISTINCTION BETWEEN ABORTTRIALTYPES\n",
    "    # annotate aborted nosepokes with '1', aborted dot offsets with -1\n",
    "    trial_data['AbortTrial'] = 0\n",
    "    abort_nosepoke = trial_data['TrialCompletionCode'].apply(lambda x: x[:-2] == 'AbortedTrial')\n",
    "    abort_dot_offset = trial_data['TrialCompletionCode'].apply(lambda x: x[:-2] == 'DotTimeLimitReached')\n",
    "    trial_data.loc[abort_nosepoke, 'AbortTrial'] = 1\n",
    "    trial_data.loc[abort_dot_offset, 'AbortTrial'] = -1\n",
    "\n",
    "    # Extract chosen port ID for all non-aborted trials\n",
    "    trial_data['ChoicePort'] = trial_data['TrialCompletionCode'].apply(lambda x: int(x[-1]))\n",
    "    trial_data.loc[trial_data['ChoicePort'] == 2, 'AbortTrial'] = 1  # Flag trials for which port 2 as aborted trials\n",
    "    trial_data.loc[trial_data['AbortTrial'] != 0, 'ChoicePort'] = np.nan  # Omit choice port for all aborted trials\n",
    "\n",
    "    # Extract correct port ID\n",
    "    trial_data['CorrectPort'] = np.nan\n",
    "    trial_data.loc[trial_data['AudioCueIdentity'] == 10, 'CorrectPort'] = 0\n",
    "    trial_data.loc[trial_data['AudioCueIdentity'] == 14, 'CorrectPort'] = 1\n",
    "\n",
    "    # Convert columns to int, filling NaN with a specific value (e.g., -1)\n",
    "    trial_data['AbortTrial'] = trial_data['AbortTrial'].astype(int)\n",
    "    trial_data['ChoicePort'] = trial_data['ChoicePort'].fillna(-1).astype(int)\n",
    "    trial_data['CorrectPort'] = trial_data['CorrectPort'].fillna(-1).astype(int)\n",
    "\n",
    "    # Reorder variables\n",
    "    cols = trial_data.columns.tolist()\n",
    "    cols.insert(cols.index('TrialNumber'), cols.pop(cols.index('Animal_ID')))\n",
    "    cols.insert(cols.index('TrialNumber'), cols.pop(cols.index('Session_ID')))\n",
    "    cols.insert(cols.index('TrialCompletionCode') + 1, cols.pop(cols.index('ChoicePort')))\n",
    "    cols.insert(cols.index('TrialCompletionCode') + 1, cols.pop(cols.index('AbortTrial')))\n",
    "    cols.insert(cols.index('TrialCompletionCode') + 1, cols.pop(cols.index('CorrectTrial')))\n",
    "    cols.insert(cols.index('ChoicePort') + 1, cols.pop(cols.index('CorrectPort')))\n",
    "    trial_data = trial_data[cols]\n",
    "\n",
    "    return trial_data\n",
    "\n",
    "# Example usage\n",
    "# trial_data = reparameterise_TrialCompletionCode(trial_data)\n",
    "\n",
    "# Import behavioral data as data frame\n",
    "experimental_data_filepath = get_experimental_data(\n",
    "    os.path.join(\n",
    "        raw_data_dir, \n",
    "        animal_ID, \n",
    "        session_ID\n",
    "    )\n",
    ")\n",
    "trials_df = pd.read_csv(experimental_data_filepath)\n",
    "\n",
    "# Rename 'DotOnsetTime' and 'DotOffsetTime' to 'DotOnsetTrigger' and 'DotOffsetTrigger'\n",
    "trials_df = trials_df.rename(\n",
    "    columns={\n",
    "        'DotOnsetTime': 'DotOnsetTrigger', \n",
    "        'DotOffsetTime': 'DotOffsetTrigger'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add animal_ID and session_ID to trials_df\n",
    "trials_df['Animal_ID'] = animal_ID\n",
    "trials_df['Session_ID'] = session_ID\n",
    "\n",
    "# Reparameterise TrialCompletionCode into more useful variables\n",
    "trials_df = reparameterise_TrialCompletionCode(trials_df)\n",
    "trials_df[['Animal_ID', 'Session_ID', 'TrialNumber', 'CorrectTrial', 'AbortTrial', 'ChoicePort', 'CorrectPort']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Align each data stream into trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align poke events with trials**\n",
    "\n",
    "Plot poke events relative to trial start times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_nose_pokes_and_trial_starts(poke_events, trials_df, start_trial_idx, end_trial_idx):\n",
    "    \"\"\"\n",
    "    Plots nose pokes and trial start times between specified trial indices.\n",
    "\n",
    "    Parameters:\n",
    "    poke_events (pd.DataFrame): DataFrame containing poke events with the following columns:\n",
    "        - 'DIPort0' (bool): Indicates if a nose poke occurred at port 0.\n",
    "        - 'DIPort1' (bool): Indicates if a nose poke occurred at port 1.\n",
    "        - 'Time' (float): Timestamp of the nose poke event.\n",
    "    trials_df (pd.DataFrame): DataFrame containing trial start times with the following column:\n",
    "        - 'TrialStart' (float): Timestamp of the trial start.\n",
    "    start_trial_idx (int): Starting index of the trial to plot.\n",
    "    end_trial_idx (int): Ending index of the trial to plot.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return any value. It displays a plot.\n",
    "    \n",
    "    Example usage:\n",
    "    plot_nose_pokes_and_trial_starts(poke_events, trials_df, 20, 30)\n",
    "    \"\"\"\n",
    "    # Filter poke events for DIPort0 or DIPort1 being True\n",
    "    poke_events_filtered = poke_events[(poke_events['DIPort0'] == True) | (poke_events['DIPort1'] == True)]\n",
    "\n",
    "    # Create a Series with the timestamp as the index and the port ID as the value\n",
    "    port_id_series = poke_events_filtered.apply(lambda row: 0 if row['DIPort0'] else 1, axis=1)\n",
    "    port_id_series.index = poke_events_filtered['Time']\n",
    "\n",
    "    # Plot the port ID Series\n",
    "    fig, ax = plt.subplots(figsize=(12, 2))\n",
    "\n",
    "    # Set y-ticks to show labels\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels(['Port 0', 'Port 1'])\n",
    "\n",
    "    # Scatter plot for port choices\n",
    "    ax.scatter(port_id_series.index, port_id_series.values, label='Port Choices')\n",
    "\n",
    "    # Mark trial start times\n",
    "    ax.vlines(trials_df['TrialStart'], 0, 1, colors='g', label='Trial Starts')\n",
    "\n",
    "    # Set plot labels\n",
    "    ax.set_xlabel('timestamp (s)')\n",
    "    ax.set_ylabel('port ID')\n",
    "    ax.set_title('Port ID vs. timestamp')\n",
    "\n",
    "    # Set x-axis limits to the start and end of the selected trials\n",
    "    ax.set_xlim(trials_df['TrialStart'].iloc[start_trial_idx], trials_df['TrialStart'].iloc[end_trial_idx])\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_nose_pokes_and_trial_starts(poke_events, trials_df, 20, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data frame with port choice ID and timestamp for each trial, where the port choice is taken as the first nose poke within the response window (between dot offset and trial end). If the trial is aborted, the port ID and timestamp are both taken as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_pokes(trial_start_times, poke_events):\n",
    "    \"\"\"\n",
    "    Parses nose poke events within each trial and returns a DataFrame with the results \n",
    "    where each row gives the timestamps and port ID of all nosepokes which occured within \n",
    "    that trial.\n",
    "\n",
    "    Args:\n",
    "        trial_start_times (pd.Series): Series of trial start times.\n",
    "        poke_events (pd.DataFrame): columns:\n",
    "            - Time: Timestamp of the event.\n",
    "            - DIPort0: Boolean in which a value changing from false to true indicates a \n",
    "            nose poke into port 0, and vice versa indicates a nosepoke out of port 0.\n",
    "            - DIPort1: Boolean in which a value changing from false to true indicates a \n",
    "            nose poke into port 1, and vice versa indicates a nosepoke out of port 1.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing nose poke events for each trial.\n",
    "    \"\"\"\n",
    "    num_trials = len(trial_start_times)\n",
    "    NosePokeIn = [[] for _ in range(num_trials)]\n",
    "    NosePokeOut = [[] for _ in range(num_trials)]\n",
    "    PortID = [[] for _ in range(num_trials)]\n",
    "    NumPokes = [0] * num_trials\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < num_trials - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = poke_events[(poke_events['Time'] >= start_time) & (poke_events['Time'] <= end_time)]\n",
    "\n",
    "        # Create lists for nose pokes within trial\n",
    "        NosePokeIn_trial, NosePokeOut_trial, PortID_trial = [], [], []\n",
    "\n",
    "        for _, nosePokeEvent in trial_events.iterrows():\n",
    "            # Get the timestamp of the event (either a nose poke in or out of a port)\n",
    "            event_time = nosePokeEvent.name\n",
    "\n",
    "            # Nose poke into port 0\n",
    "            if nosePokeEvent.DIPort0:\n",
    "                NosePokeIn_trial.append(event_time)\n",
    "                PortID_trial.append(0)\n",
    "\n",
    "            # Nose poke into port 1\n",
    "            elif nosePokeEvent.DIPort1:\n",
    "                NosePokeIn_trial.append(event_time)\n",
    "                PortID_trial.append(1)\n",
    "\n",
    "            # Nose poke out of port 0 or port 1\n",
    "            elif not nosePokeEvent.DIPort0 and not nosePokeEvent.DIPort1:\n",
    "                NosePokeOut_trial.append(event_time)\n",
    "\n",
    "        NosePokeIn[i] = NosePokeIn_trial\n",
    "        NosePokeOut[i] = NosePokeOut_trial\n",
    "        PortID[i] = PortID_trial\n",
    "        NumPokes[i] = len(NosePokeIn_trial)\n",
    "\n",
    "    trial_pokes_df = pd.DataFrame({\n",
    "        'NosePokeIn': NosePokeIn,\n",
    "        'NosePokeOut': NosePokeOut,\n",
    "        'PortID': PortID,\n",
    "        'NumPokes': NumPokes\n",
    "    })\n",
    "\n",
    "    return trial_pokes_df\n",
    "\n",
    "trial_pokes_df = parse_trial_pokes(trials_df['TrialStart'], poke_events)\n",
    "\n",
    "# Plot histogram of NumPokes\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "trial_pokes_df['NumPokes'].hist(ax=ax)\n",
    "ax.set_xlabel('Number of pokes')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Histogram of number of pokes per trial')\n",
    "plt.show()\n",
    "\n",
    "trial_pokes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align sound events to trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_sounds(trial_start_times, sound_events, OFF_index=18):\n",
    "\n",
    "    # Create lists to store the poke IDs and timestamps for all trials\n",
    "    ON_S, OFF_S, ID_S = [], [], []\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < len(trial_start_times) - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = sound_events[(sound_events.Time >= start_time) & (sound_events.Time <= end_time)]\n",
    "\n",
    "        # Create trial lists for sounds this trial\n",
    "        ON, OFF, ID = [], [], []\n",
    "        for _, sound in trial_events.iterrows():\n",
    "            event_time = sound.Time\n",
    "            sound = sound[['PlaySoundOrFrequency']]\n",
    "            sound = int(sound.iloc[0])\n",
    "\n",
    "            # Find audio IDs from the value. Only find ID for OFFSET\n",
    "            if sound != OFF_index:\n",
    "                ON.append(event_time)\n",
    "                ID.append(sound)\n",
    "            else:\n",
    "                OFF.append(event_time)\n",
    "\n",
    "        ON_S.append(ON)\n",
    "        OFF_S.append(OFF)\n",
    "        ID_S.append(ID)\n",
    "        \n",
    "    trial_sounds_df = pd.DataFrame({'AudioCueStartTimes': ON_S, 'AudioCueEndTimes': OFF_S, 'AudioCueIdentities': ID_S})  # Create dataframe from all nosepoke events\n",
    "\n",
    "    return trial_sounds_df\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial\n",
    "trial_sounds_df = parse_trial_sounds(trials_df['TrialStart'], sound_events)\n",
    "\n",
    "# Append sound ID to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_sounds_df],axis=1)\n",
    "\n",
    "# Show sound data frame\n",
    "trial_sounds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save trials_df dataframe for further analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trials_df as a .pkl file to be used for further analysis\n",
    "# session_output_dir = os.path.join(output_dir, animal_ID, session_ID)\n",
    "# trials_df.to_pickle(os.path.join(session_output_dir, animal_ID + '_' + session_ID + '_trial_data_harp.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse photodiode data into dot onset, dot onset and fail state events within each trial**\n",
    "\n",
    "Parse photodiode data into a time series with 3 distinct states:\n",
    "- 0 indicates a resting state\n",
    "- 1 indicates a state in which the dot is projected\n",
    "- 2 indicates a fail state (in which the arena lights are on)\n",
    "\n",
    "1. Apply the dot onset threshold (2000AU) to the raw signal to distinguish state 0 from states 1 and 2\n",
    "2. Take average of signal for each instances of states 1 and 2 and distinguish them with a second fail state threshold (3922AU)\n",
    "\n",
    "**Note!**: the outputs from this method will have to be checked for instances in stage 5 where we go straight from state 1 to state 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square_wave(df): \n",
    "\n",
    "    # Create a new DataFrame with repeated elements\n",
    "    square_wave = {'timestamp': df['timestamp'].repeat(2).tolist()[1:],\n",
    "        'state': df['state'].repeat(2).tolist()[:-1]\n",
    "        }\n",
    "    square_wave = pd.DataFrame(square_wave)\n",
    "    return square_wave\n",
    "\n",
    "def map_photodiode_state(dot_on_threshold, fail_state_threshold, photodiode_data):\n",
    "\n",
    "    # Map values to 0 or 1 based on the threshold using a lambda function\n",
    "    photodiode_state = photodiode_data.apply(lambda x: 0 if x < dot_on_threshold else 1)\n",
    "\n",
    "    # Get indices at which photodiode state changes\n",
    "    photodiode_state_diff = photodiode_state.diff()\n",
    "    photodiode_state_change_indices = pd.Index([photodiode_state.index[0]]).union(\n",
    "        photodiode_state_diff[photodiode_state_diff != 0].index\n",
    "    )\n",
    "\n",
    "    # Iterate through the indices of state changes\n",
    "    rows = []\n",
    "    for i in range(len(photodiode_state_change_indices) - 1):\n",
    "        start_idx = photodiode_state_change_indices[i]\n",
    "        end_idx = photodiode_state_change_indices[i + 1]\n",
    "        state = photodiode_state[start_idx]\n",
    "        avg_signal = photodiode_data[start_idx:end_idx].mean()\n",
    "        rows.append([start_idx, state, avg_signal])\n",
    "\n",
    "    # Handle the last state change to the end of the series\n",
    "    start_idx = photodiode_state_change_indices[-1]\n",
    "    state = photodiode_state[start_idx]\n",
    "    avg_signal = photodiode_data[start_idx:].mean()\n",
    "    rows.append([start_idx, state, avg_signal])\n",
    "\n",
    "    photodiode_state_df = pd.DataFrame(rows, columns=['timestamp', 'state', 'AvgPhotodiodeSignal'])\n",
    "\n",
    "    # Mark state 2 (fail state) based on a second threshold\n",
    "    photodiode_state_df['state'] = photodiode_state_df.apply(\n",
    "        lambda row: 2 if row['AvgPhotodiodeSignal'] > fail_state_threshold else row['state'], axis=1\n",
    "    )\n",
    "\n",
    "    return photodiode_state_df\n",
    "\n",
    "dot_on_threshold = 3000\n",
    "fail_state_threshold = 3922\n",
    "\n",
    "photodiode_state_df = map_photodiode_state(dot_on_threshold, fail_state_threshold, photodiode_data)\n",
    "\n",
    "# Get a Series where the index is Timestamp from df_state_changes and the values are State\n",
    "photodiode_state = pd.Series(photodiode_state_df['state'].values, index=photodiode_state_df['timestamp'])\n",
    "\n",
    "# Plot the diode trace, draw points at the TTL onsets. Restrict plot to chosen trial (2 seconds either side of TTL)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.xlim(t_start-2, t_end+2)\n",
    "state_changes_trace = get_square_wave(photodiode_state_df)\n",
    "plt.plot(state_changes_trace['timestamp'], state_changes_trace['state'], label='Photodiode State')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "photodiode_state_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
