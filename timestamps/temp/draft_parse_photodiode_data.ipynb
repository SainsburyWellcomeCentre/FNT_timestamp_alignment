{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and script to interface with recorded Harp Binaries\n",
    "\n",
    "**Inputs:**\n",
    "- Binary files in session folder saved in 'Behavior.harp', and 'SoundCard.harp' subdirectories.<br>\n",
    "- Experimental data .csv file in 'Experimental-data' subdirectory containing trial-level behavioural data output directory from Bonsai workflow.\n",
    "\n",
    "**Key outputs**\n",
    "- trials_df data frame containing a summary of behavioural events in each trial including harp timestamps for dot onset and offset, nose pokes, and audio onset and offset times within each trial. Note that this data set contains redundancy to double check consistency of trial information between this script and the Bonsai output. \n",
    "\n",
    "**Overview** \n",
    "1. Create a general reader for the harp behavior board binaries and another specifically for register 32 of the sound card.\n",
    "2. Align key behavioural events to trials in a pandas data frame in which each row represents one trial. \n",
    "3. Append harp data frame to behavioural summary data frame containing trial-level information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries and define data folder\n",
    "import harp\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.harp_utils as hu\n",
    "import utils.plot_utils as pu\n",
    "\n",
    "#==============================================================================\n",
    "animal_ID = 'FNT099'\n",
    "session_ID = '2024-05-13T11-03-59'\n",
    "\n",
    "# animal_ID = 'FNT107'\n",
    "# session_ID = '2024-08-11T14-01-24'\n",
    "\n",
    "# path behavioural data on ceph repo\n",
    "input_dir = r\"W:\\projects\\FlexiVexi\\raw_data\" \n",
    "output_dir = (r\"C:\\Users\\megan\\Documents\\sjlab\\flexible-navigation-task\" +\n",
    "              r\"\\data_analysis\\intermediate_variables\")\n",
    "\n",
    "#==============================================================================\n",
    "\n",
    "# Create reader for behavior.\n",
    "bin_b_path = os.path.join(input_dir, animal_ID, session_ID, \"Behavior.harp\")\n",
    "behavior_reader = harp.create_reader(bin_b_path)\n",
    "\n",
    "# Specify mapping from sound index to reward port\n",
    "soundIdx0 = 14\n",
    "soundIdx1 = 10\n",
    "soundOffIdx = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get harp TTL data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "def plot_ttl_trace(ttl_state_df, *, t_start, t_end):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 2))  # Set the figure size (width, height) in inches\n",
    "    ttl_pulse = hu.get_square_wave(ttl_state_df)\n",
    "    ttl_pulse.plot(x='timestamp', y='state', linewidth=0.5, ax=ax)\n",
    "    ax.set_xlabel('timestamp (s)')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlim(t_start, t_end)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "# Get data frame with state of TTL pulse\n",
    "ttl_state_df = hu.get_ttl_state_df(behavior_reader)\n",
    "\n",
    "# Plot ttl trace\n",
    "t0 = ttl_state_df['timestamp'].iloc[0]\n",
    "\n",
    "fig, ax = plot_ttl_trace(ttl_state_df, t_start=t0, t_end=t0 + 40)\n",
    "ax.set_title(\"Plot TTL pulses, \" + session_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align dot times with experimental-data-csv**\n",
    " \n",
    " --> Need to phase out of using this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import behavioral data as data frame\n",
    "session_path = os.path.join(input_dir, animal_ID, session_ID)\n",
    "filepath = os.path.join(session_path, 'Experimental-data', session_ID + '_experimental-data.csv')\n",
    "trials_df = pd.read_csv(filepath)\n",
    "\n",
    "# Get dot onset and offset times given by TTL pulses\n",
    "\n",
    "## First dot onset time from software clock (used as a common sense check for inconsistencies with number of TTL pulses on start up)\n",
    "t0 = trials_df['DotOnsetTime'].iloc[0]\n",
    "\n",
    "## Get dot times from TTL pulses\n",
    "[dot_times_ttl, ttl_state_0] = hu.get_dot_times_from_ttl(behavior_reader, t0, return_TTL_state_at_startup=True)\n",
    "print('TTL state upon start-up: ', ttl_state_0)\n",
    "\n",
    "# Append dot onset and offset times given by TTL pulses to trials_df\n",
    "trials_df = pd.concat([trials_df, dot_times_ttl],axis=1)\n",
    "\n",
    "# Common sense check that the logic of aligning the TTL pulses is working as expected.\n",
    "# Check dot onset and times from software clock TTL pulses are consistent, given by:\n",
    "# - DotOnsetTime = dot onset time from software clock\n",
    "# - DotOnsetTime_ttl = dot onset time from TTL pulses\n",
    "# - DotOffsetTime = dot offset time from software clock\n",
    "# - DotOffsetTime_ttl = dot offset time from TTL pulses\n",
    "\n",
    "trials_df[['TrialStart', 'DotOnsetTime', 'DotOffsetTime', 'DotOnsetTime_harp_ttl', 'DotOffsetTime_harp_ttl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all poke events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the behavior harp stream, Digital Input states for the nosepoke timestamps and IDs. Drop DI3 <-- What's DI3??\n",
    "all_pokes = behavior_reader.DigitalInputState.read()\n",
    "\n",
    "all_pokes.drop(columns=['DI3','DIPort2'],inplace = True) # remove all nose pokes to dummy port\n",
    "#all_pokes.reset_index(inplace=True)\n",
    "\n",
    "# Show resulting data frame\n",
    "all_pokes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all audio events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sound card binary data (register 32) and show resulting dataframe\n",
    "bin_sound_path = os.path.join(input_dir, animal_ID, session_ID, \"SoundCard.harp\",\"SoundCard_32.bin\")\n",
    "\n",
    "# Read the harp sound card stream, for the timestamps and audio ID\n",
    "all_sounds = hu.get_all_sounds(bin_sound_path)\n",
    "\n",
    "# Show dataframe\n",
    "all_sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get trial start times in harp clock**\n",
    "This will be redundant in our final version of the code! We don't want to define trail start in stage 4 by TTL data or photodiode data since both are too error prone. Instead, move to TrailStart from Bonsai output (currently 'experimental-data.csv')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check training stage specified in 'trials_df'\n",
    "stage = trials_df['TrainingStage'].iloc[0]\n",
    "\n",
    "# get trial start times for the specified stage\n",
    "if stage == 4:\n",
    "    dot_onset_times = trials_df['DotOnsetTime_harp_ttl']\n",
    "    trial_start_times = hu.get_trial_start_times(4, dot_onset_times=dot_onset_times)\n",
    "elif stage == 5:\n",
    "    trial_start_times = hu.get_trial_start_times(5, bin_sound_path=bin_sound_path, sound_reader=sound_reader)\n",
    "\n",
    "# Append trial start times to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_start_times.rename('TrialStart_harp')],axis=1)\n",
    "\n",
    "trials_df[['TrialStart', 'TrialStart_harp', 'DotOnsetTime', 'DotOffsetTime', 'DotOnsetTime_harp_ttl', 'DotOffsetTime_harp_ttl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align poke events with trials**\n",
    "\n",
    "Get data frame with port choice ID and timestamp for each trial, where the port choice is taken as the first nose poke within the response window (between dot offset and trial end). If the trial is aborted, the port ID and timestamp are both taken as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data frame with port choice ID and timestamp for each trial\n",
    "port_choice_df = hu.get_port_choice(trials_df, behavior_reader)\n",
    "\n",
    "# Append port choice to trials_df\n",
    "trials_df = pd.concat([trials_df, port_choice_df],axis=1)\n",
    "\n",
    "# Show port choice data frame\n",
    "port_choice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align sound events to trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_sounds(trial_start_times, bin_sound_path, OFF_index=18):\n",
    "    # Read the harp sound card stream, for the timestamps and audio ID\n",
    "    all_sounds = hu.get_all_sounds(bin_sound_path)\n",
    "\n",
    "    # Create lists to store the poke IDs and timestamps for all trials\n",
    "    ON_S, OFF_S, ID_S = [], [], []\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < len(trial_start_times) - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = all_sounds[(all_sounds.Time >= start_time) & (all_sounds.Time <= end_time)]\n",
    "\n",
    "        # Create trial lists for sounds this trial\n",
    "        ON, OFF, ID = [], [], []\n",
    "        for _, sound in trial_events.iterrows():\n",
    "            event_time = sound.Time\n",
    "            sound = sound[['PlaySoundOrFrequency']]\n",
    "            sound = int(sound.iloc[0])\n",
    "\n",
    "            # Find audio IDs from the value. Only find ID for OFFSET\n",
    "            if sound != OFF_index:\n",
    "                ON.append(event_time)\n",
    "                ID.append(sound)\n",
    "            else:\n",
    "                OFF.append(event_time)\n",
    "\n",
    "        ON_S.append(ON)\n",
    "        OFF_S.append(OFF)\n",
    "        ID_S.append(ID)\n",
    "        \n",
    "    trial_sounds_df = pd.DataFrame({'AudioCueStart_harp': ON_S, 'AudioCueEnd_harp': OFF_S, 'AudioCueIdentity_harp': ID_S})  # Create dataframe from all nosepoke events\n",
    "\n",
    "    return trial_sounds_df\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial\n",
    "trial_sounds_df = parse_trial_sounds(trials_df['TrialStart'], bin_sound_path)\n",
    "\n",
    "# Append sound ID to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_sounds_df],axis=1)\n",
    "\n",
    "# Show sound data frame\n",
    "trial_sounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check trials_df AudioCueStart and ChoicePort is as expected\n",
    "trials_df[\n",
    "    [\n",
    "        'TrialStart',\n",
    "        'TrialStart_harp',\n",
    "        'TrialCompletionCode',\n",
    "        'ChoicePort',\n",
    "        'ChoiceTimestamp',\n",
    "        'AudioCueStart_harp',\n",
    "        'AudioCueEnd_harp',\n",
    "        'AudioCueIdentity'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save trials_df dataframe for further analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trials_df as a .pkl file to be used for further analysis\n",
    "# session_output_dir = os.path.join(output_dir, animal_ID, session_ID)\n",
    "# trials_df.to_pickle(os.path.join(session_output_dir, animal_ID + '_' + session_ID + '_trial_data_harp.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get photodiode data -- work in progress!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab photodiode data\n",
    "photodiode = behavior_reader.AnalogData.read()\n",
    "\n",
    "# Keep only Time and AnalogInput0 columns\n",
    "photodiode = photodiode['AnalogInput0']\n",
    "\n",
    "# smooth photodiode signal over 100 samples (0.1 seconds)\n",
    "photodiode_smoothed = photodiode.rolling(window=100, center=True).mean()\n",
    "# # Choose trials to plot\n",
    "trial_start_num = 10\n",
    "trial_end_num=11\n",
    "\n",
    "# Find Timestamps for these trials\n",
    "t_start = trials_df['TrialStart_harp'].iloc[trial_start_num]\n",
    "t_end = trials_df['TrialStart_harp'].iloc[trial_end_num+1]\n",
    "\n",
    "\n",
    "# get timestamps of start of aborted trials from trials_df\n",
    "aborted_trials = trials_df[trials_df['ChoicePort'] == -1]\n",
    "\n",
    "ttl_onset_times = ttl_state_df[ttl_state_df['state'] == 1]['timestamp']\n",
    "ttl_offset_times = ttl_state_df[ttl_state_df['state'] == 0]['timestamp']\n",
    "\n",
    "# # plot the diode trace, draw points at the TTL onsets. Restrict plot to chosen trial (2 seconds either side of TTL)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.xlim(t_start-2, t_end+2)\n",
    "plt.xlim(t_start+20, t_start+25)\n",
    "\n",
    "plt.ylim(0, 4000)\n",
    "plt.plot(photodiode, label = 'Photodiode Signal')\n",
    "plt.plot(photodiode_smoothed, label = 'Smoothed Photodiode Signal')\n",
    "plt.vlines(ttl_onset_times, ymin=photodiode.min(), ymax=photodiode.max(), color='r', linestyle='--', label='TTL Onset')\n",
    "plt.xlabel('Time (Harp timestamps)')\n",
    "plt.ylabel('AU')\n",
    "plt.legend(loc = 'upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a reasonable threshold to distinguish between the \"Dot on\" and \"Fail State On\" states of the smoothed photodiode signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histogram of smoothed photodiode signal values for values above 3900\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(photodiode_smoothed[photodiode_smoothed > 3900], bins=100)\n",
    "plt.xlabel('Photodiode Signal Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Smoothed Photodiode Signal Values')\n",
    "\n",
    "fail_state_threshold = 3922\n",
    "\n",
    "# mark abort state threshold on x-axis of histogram\n",
    "plt.axvline(x=fail_state_threshold, color='r', linestyle='--', label='Fail State Threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1** \n",
    "Try smoothing and binning into 3 distinct states:\n",
    "- 0 indicates a resting state\n",
    "- 1 indicates a state in which the dot is projected\n",
    "- 2 indicates a fail state (in which the arena lights are on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_on_threshold = 3000 # (Set on the higher end so it is more robust to noise if door is open)\n",
    "fail_state_threshold = 3922\n",
    "\n",
    "# Function to map values to 0, 1, or 2 based on the thresholds\n",
    "def map_photodiode_state(photodiode_signal):\n",
    "    if photodiode_signal < dot_on_threshold:\n",
    "        return 0\n",
    "    elif dot_on_threshold <= photodiode_signal < fail_state_threshold:\n",
    "        return 1\n",
    "    elif photodiode_signal >= fail_state_threshold:\n",
    "        return 2\n",
    "\n",
    "photodiode_state = photodiode_smoothed.apply(map_photodiode_state)\n",
    "\n",
    "# # plot the diode trace, draw points at the TTL onsets. Restrict plot to chosen trial (2 seconds either side of TTL)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.xlim(t_start-2, t_end+2)\n",
    "plt.plot(photodiode_state, label = 'Photodiode State')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2** Apply threshold to local minima\n",
    "1. Get y-values of all minima in raw photodiode signal\n",
    "2. Apply thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# Get indices of local minima in the photodiode signal\n",
    "minima_indices = argrelextrema(photodiode.values, np.less)[0]\n",
    "\n",
    "# Convert integer indices to time-based indices\n",
    "minima_time_indices = photodiode.index[minima_indices]\n",
    "\n",
    "# Get a time series of all local minima in photodiode signal\n",
    "minima_ts = photodiode.loc[minima_time_indices]\n",
    "\n",
    "# # Get the values and timestamps of the minima\n",
    "# minima_values = photodiode.loc[minima_time_indices, 'AnalogInput0']\n",
    "# minima_timestamps = minima_time_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the photodiode signal between t_start and t_end with minima marked\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.xlim(t_start-2, t_end+2)\n",
    "plt.xlim(t_start+20, t_start+25)\n",
    "\n",
    "plt.plot(photodiode, label = 'Photodiode Signal', zorder=1)\n",
    "plt.scatter(minima_ts.index, minima_ts.values, color='r', label='Minima', s=5, zorder =2)\n",
    "plt.xlabel('Time (Harp timestamps)')\n",
    "plt.ylabel('AU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3** Thresholding and averaging \n",
    "\n",
    "1. Apply the dot onset threshold (2000AU) to the raw signal to distinguish state 0 from states 1 and 2\n",
    "2. Take average of signal for each instances of states 1 and 2 and distinguish them with a second fail state threshold (3922AU)\n",
    "\n",
    "**Note!**: the outputs from this method will have to be checked for instances in stage 5 where we go straight from state 1 to state 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square_wave(df): \n",
    "\n",
    "    # Create a new DataFrame with repeated elements\n",
    "    square_wave = {'timestamp': df['timestamp'].repeat(2).tolist()[1:],\n",
    "        'state': df['state'].repeat(2).tolist()[:-1]\n",
    "        }\n",
    "    square_wave = pd.DataFrame(square_wave)\n",
    "    return square_wave\n",
    "\n",
    "def map_photodiode_state(dot_on_threshold, fail_state_threshold, photodiode):\n",
    "\n",
    "    # Map values to 0 or 1 based on the threshold using a lambda function\n",
    "    photodiode_state = photodiode.apply(lambda x: 0 if x < dot_on_threshold else 1)\n",
    "\n",
    "    # Get indices at which photodiode state changes\n",
    "    photodiode_state_diff = photodiode_state.diff()\n",
    "    photodiode_state_change_indices = pd.Index([photodiode_state.index[0]]).union(\n",
    "        photodiode_state_diff[photodiode_state_diff != 0].index\n",
    "    )\n",
    "\n",
    "    # Iterate through the indices of state changes\n",
    "    rows = []\n",
    "    for i in range(len(photodiode_state_change_indices) - 1):\n",
    "        start_idx = photodiode_state_change_indices[i]\n",
    "        end_idx = photodiode_state_change_indices[i + 1]\n",
    "        state = photodiode_state[start_idx]\n",
    "        avg_signal = photodiode[start_idx:end_idx].mean()\n",
    "        rows.append([start_idx, state, avg_signal])\n",
    "\n",
    "    # Handle the last state change to the end of the series\n",
    "    start_idx = photodiode_state_change_indices[-1]\n",
    "    state = photodiode_state[start_idx]\n",
    "    avg_signal = photodiode[start_idx:].mean()\n",
    "    rows.append([start_idx, state, avg_signal])\n",
    "\n",
    "    photodiode_state_df = pd.DataFrame(rows, columns=['timestamp', 'state', 'AvgPhotodiodeSignal'])\n",
    "\n",
    "    # Mark state 2 (fail state) based on a second threshold\n",
    "    photodiode_state_df['state'] = photodiode_state_df.apply(\n",
    "        lambda row: 2 if row['AvgPhotodiodeSignal'] > fail_state_threshold else row['state'], axis=1\n",
    "    )\n",
    "\n",
    "    return photodiode_state_df\n",
    "\n",
    "dot_on_threshold = 3000\n",
    "fail_state_threshold = 3922\n",
    "\n",
    "photodiode_state_df = map_photodiode_state(dot_on_threshold, fail_state_threshold, photodiode)\n",
    "\n",
    "# Get a Series where the index is Timestamp from df_state_changes and the values are State\n",
    "photodiode_state = pd.Series(photodiode_state_df['state'].values, index=photodiode_state_df['timestamp'])\n",
    "\n",
    "# Plot the diode trace, draw points at the TTL onsets. Restrict plot to chosen trial (2 seconds either side of TTL)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.xlim(t_start-2, t_end+2)\n",
    "state_changes_trace = get_square_wave(photodiode_state_df)\n",
    "plt.plot(state_changes_trace['timestamp'], state_changes_trace['state'], label='Photodiode State')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "photodiode_state_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
