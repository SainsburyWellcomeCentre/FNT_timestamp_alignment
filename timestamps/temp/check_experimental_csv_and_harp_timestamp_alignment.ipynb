{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get harp TTL data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries and define data folder\n",
    "import harp\n",
    "import pandas as pd\n",
    "from harp.model import Model, Register, Access\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.harp_utils as hu\n",
    "\n",
    "#==============================================================================\n",
    "animal_ID = 'FNT099'\n",
    "session_ID = '2024-05-13T11-03-59'\n",
    "session_ID = '2024-03-13T10-49-40'\n",
    "\n",
    "# animal_ID = 'FNT107'\n",
    "# session_ID = '2024-08-11T14-01-24'\n",
    "\n",
    "# path behavioural data on ceph repo\n",
    "input_dir = Path(\"W:/projects/FlexiVexi/raw_data\")\n",
    "output_dir = Path(\"C:/Users/megan/Documents/sjlab/flexible-navigation-task\" +\n",
    "              r\"/data_analysis/intermediate_variables\")\n",
    "\n",
    "#==============================================================================\n",
    "\n",
    "# Create reader for behavior.\n",
    "bin_b_path = input_dir / animal_ID / session_ID / \"Behavior.harp\"\n",
    "behavior_reader = harp.create_reader(bin_b_path)\n",
    "\n",
    "# Specify mapping from sound index to reward port\n",
    "soundIdx0 = 14\n",
    "soundIdx1 = 10\n",
    "soundOffIdx = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align dot times with experimental-data-csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import behavioral data as data frame\n",
    "session_path = input_dir / animal_ID / session_ID\n",
    "filepath = session_path / 'Experimental-data' / (session_ID + '_experimental-data.csv')\n",
    "trials_df = pd.read_csv(filepath)\n",
    "\n",
    "# Get dot onset and offset times given by TTL pulses\n",
    "\n",
    "## First dot onset time from software clock (used as a common sense check for inconsistencies with number of TTL pulses on start up)\n",
    "t0 = trials_df['DotOnsetTime'].iloc[0]\n",
    "\n",
    "## Get dot times from TTL pulses\n",
    "[dot_times_ttl, ttl_state_0] = hu.get_dot_times_from_ttl(behavior_reader, t0, return_TTL_state_at_startup=True)\n",
    "print('TTL state upon start-up: ', ttl_state_0)\n",
    "\n",
    "# Append dot onset and offset times given by TTL pulses to trials_df\n",
    "trials_df = pd.concat([trials_df, dot_times_ttl],axis=1)\n",
    "# rename 'DotOnsetTime' and 'DotOffsetTime' columns to 'DotOnsetTime_harp' and 'DotOffsetTime_harp'\n",
    "trials_df.rename(columns = {\n",
    "        'DotOnsetTime_ttl':'DotOnsetTime_harp', \n",
    "        'DotOffsetTime_ttl':'DotOffsetTime_harp'\n",
    "        }, \n",
    "    inplace = True)\n",
    "\n",
    "# Common sense check that the logic of aligning the TTL pulses is working as expected.\n",
    "# Check dot onset and times from software clock TTL pulses are consistent, given by:\n",
    "# - DotOnsetTime = dot onset time from software clock\n",
    "# - DotOnsetTime_ttl = dot onset time from TTL pulses\n",
    "# - DotOffsetTime = dot offset time from software clock\n",
    "# - DotOffsetTime_ttl = dot offset time from TTL pulses\n",
    "\n",
    "trials_df[['TrialStart', 'DotOnsetTime', 'DotOffsetTime', 'DotOnsetTime_harp', 'DotOffsetTime_harp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all poke events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the behavior harp stream, Digital Input states for the nosepoke timestamps and IDs. Drop DI3 <-- What's DI3??\n",
    "all_pokes = behavior_reader.DigitalInputState.read()\n",
    "\n",
    "all_pokes.drop(columns=['DI3','DIPort2'],inplace = True) # remove all nose pokes to dummy port\n",
    "#all_pokes.reset_index(inplace=True)\n",
    "\n",
    "# Show resulting data frame\n",
    "all_pokes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all audio events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.harp_utils as hu\n",
    "# Load the sound card binary data (register 32) and show resulting dataframe\n",
    "bin_sound_path = os.path.join(input_dir, animal_ID, session_ID, \"SoundCard.harp\",\"SoundCard_32.bin\")\n",
    "\n",
    "# the explicitly defined model will be deprecated or redundant in future\n",
    "model = Model(device='Soundcard', whoAmI=1280,firmwareVersion='2.2',hardwareTargets='1.1',registers={'PlaySoundOrFrequency': Register(address=32, type=\"U16\", access=Access.Event)})\n",
    "sound_reader = harp.create_reader(model, keep_type=True)\n",
    "\n",
    "# Read the harp sound card stream, for the timestamps and audio ID\n",
    "all_sounds = hu.get_all_sounds(sound_reader, bin_sound_path)\n",
    "\n",
    "# Show dataframe (maybe)\n",
    "all_sounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get trial start times in harp clock**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check training stage specified in 'trials_df'\n",
    "stage = trials_df['TrainingStage'].iloc[0]\n",
    "\n",
    "# get trial start times for the specified stage\n",
    "if stage == 4:\n",
    "    dot_onset_times = trials_df['DotOnsetTime_harp']\n",
    "    trial_start_times = hu.get_trial_start_times(4, dot_onset_times=dot_onset_times)\n",
    "elif stage == 5:\n",
    "    trial_start_times = hu.get_trial_End_times(5, bin_sound_path=bin_sound_path, sound_reader=sound_reader)\n",
    "\n",
    "# Append trial start times to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_start_times.rename('TrialStart_harp')],axis=1)\n",
    "\n",
    "trials_df[['TrialStart', 'TrialStart_harp', 'DotOnsetTime', 'DotOffsetTime', 'DotOnsetTime_harp', 'DotOffsetTime_harp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align poke events with trials**\n",
    "\n",
    "Get data frame with port choice ID and timestamp for each trial, where the port choice is taken as the first nose poke within the response window (between dot offset and trial end). If the trial is aborted, the port ID and timestamp are both taken as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.harp_utils as hu\n",
    "\n",
    "# Get data frame with port choice ID and timestamp for each trial\n",
    "port_choice_df = hu.get_port_choice(trials_df, behavior_reader)\n",
    "\n",
    "# Append port choice to trials_df\n",
    "trials_df = pd.concat([trials_df, port_choice_df],axis=1)\n",
    "\n",
    "# Show port choice data frame\n",
    "port_choice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align sound events to trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_sounds(trial_start_times, sound_reader, bin_sound_path, OFF_index=18):\n",
    "    # Read the harp sound card stream, for the timestamps and audio ID\n",
    "    all_sounds = hu.get_all_sounds(sound_reader, bin_sound_path)\n",
    "\n",
    "    # Create lists to store the poke IDs and timestamps for all trials\n",
    "    ON_S, OFF_S, ID_S = [], [], []\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < len(trial_start_times) - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = all_sounds[(all_sounds.Time >= start_time) & (all_sounds.Time <= end_time)]\n",
    "\n",
    "        # Create trial lists for sounds this trial\n",
    "        ON, OFF, ID = [], [], []\n",
    "        for _, sound in trial_events.iterrows():\n",
    "            event_time = sound.Time\n",
    "            sound = sound[['PlaySoundOrFrequency']]\n",
    "            sound = int(sound.iloc[0])\n",
    "\n",
    "            # Find audio IDs from the value. Only find ID for OFFSET\n",
    "            if sound != OFF_index:\n",
    "                ON.append(event_time)\n",
    "                ID.append(sound)\n",
    "            else:\n",
    "                OFF.append(event_time)\n",
    "\n",
    "        ON_S.append(ON)\n",
    "        OFF_S.append(OFF)\n",
    "        ID_S.append(ID)\n",
    "        \n",
    "    trial_sounds_df = pd.DataFrame({'AudioCueStart_harp': ON_S, 'AudioCueEnd_harp': OFF_S, 'AudioCueIdentity_harp': ID_S})  # Create dataframe from all nosepoke events\n",
    "\n",
    "    return trial_sounds_df\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial\n",
    "trial_sounds_df = parse_trial_sounds(trials_df['TrialStart_harp'], sound_reader, bin_sound_path)\n",
    "\n",
    "# Append sound ID to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_sounds_df],axis=1)\n",
    "\n",
    "# Show sound data frame\n",
    "trial_sounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check trials_df AudioCueStart and ChoicePort is as expected\n",
    "trials_df[\n",
    "    [\n",
    "        'TrialStart',\n",
    "        'TrialStart_harp',\n",
    "        'TrialCompletionCode',\n",
    "        'ChoicePort',\n",
    "        'ChoiceTimestamp',\n",
    "        'AudioCueStart_harp',\n",
    "        'AudioCueEnd_harp',\n",
    "        'AudioCueIdentity'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistency of harp clock timestamps with experimental-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DotOnsetTime and TrialStart are distinct on stage 4.1 in experimental-data.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take difference between TrialStart and DotOnsetTime_harp\n",
    "test = trials_df['TrialStart'] - trials_df['DotOnsetTime']\n",
    "\n",
    "# Get histogram of differences between DotOnsetTime_harp and DotOnsetTime\n",
    "fig, ax = plt.subplots()\n",
    "test.hist(bins=100, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial start time inferred from TTL pulses has some jitter relative to TrialStart (or DotOnset) in experimental-data.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take difference between TrialStart and DotOnsetTime_harp\n",
    "trials_df['DotOnsetTime_harp_diff'] = trials_df['DotOnsetTime_harp'] - trials_df['TrialStart']\n",
    "print(sum(trials_df['DotOnsetTime_harp_diff'] < 0))\n",
    "# Get histogram of differences between DotOnsetTime_harp and DotOnsetTime\n",
    "fig, ax = plt.subplots()\n",
    "trials_df['DotOnsetTime_harp_diff'].hist(bins=100, ax=ax)\n",
    "ax.set_title('Histogram of differences between DotOnsetTime_harp and TrialStart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp of nosepoke for port choice is identical in both experimental-data.csv and harp binary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take difference between TrialStart and DotOnsetTime_harp\n",
    "trials_df['choiceTimestamp_diff'] = trials_df['ChoiceTimestamp'] - trials_df['NosepokeInTime']\n",
    "\n",
    "# Get histogram of differences between DotOnsetTime_harp and DotOnsetTime\n",
    "fig, ax = plt.subplots()\n",
    "trials_df['choiceTimestamp_diff'].hist(bins=100, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare sound onset time in experimental-data.csv to sound onset in harp time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df[\n",
    "    [\n",
    "        'AudioCueStart',\n",
    "        'AudioCueStart_harp',\n",
    "        'AudioCueEnd',\n",
    "        'AudioCueEnd_harp',\n",
    "        'AudioCueIdentity'\n",
    "    ]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioCueStart in experimental-data.csv matches the final instance of Audio Cue Onset from harp binaries within the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Get difference between AudioCueStart and first value of AudioCueStart_harp\n",
    "trials_df['AudioCueStart_diff'] = trials_df['AudioCueStart'] - trials_df['AudioCueStart_harp'].apply(lambda x: x[0])\n",
    "\n",
    "# Plot histogram of differences between AudioCueStart in harp binary file versus AudioCueStart in .csv\n",
    "trials_df['AudioCueStart_diff'].hist(bins=100, ax=axs[0])\n",
    "axs[0].set_title('Difference between AudioCueStart\\nand first value of AudioCueStart_harp')\n",
    "\n",
    "# Get difference between AudioCueStart and last value of AudioCueStart_harp\n",
    "trials_df['AudioCueStart_diff'] = trials_df['AudioCueStart'] - trials_df['AudioCueStart_harp'].apply(lambda x: x[-1])\n",
    "\n",
    "# Plot histogram of differences between AudioCueStart in harp binary file versus AudioCueStart in .csv\n",
    "trials_df['AudioCueStart_diff'].hist(bins=100, ax=axs[1])\n",
    "axs[1].set_title('Difference between AudioCueStart\\nand last value of AudioCueStart_harp')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioCueEnd from experimental-data.csv deviates significantly from first or last Audio Cue End from harp binaries in many trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Get difference between AudioCueEnd and first value of AudioCueEnd_harp\n",
    "trials_df['AudioCueEnd_diff'] = trials_df['AudioCueEnd'] - trials_df['AudioCueEnd_harp'].apply(lambda x: x[0])\n",
    "\n",
    "# Plot histogram of differences between AudioCueEnd in harp binary file versus AudioCueEnd in .csv\n",
    "trials_df['AudioCueEnd_diff'].hist(bins=100, ax=axs[0])\n",
    "axs[0].set_title('Difference between AudioCueEnd\\nand first value of AudioCueEnd_harp')\n",
    "\n",
    "# Get difference between AudioCueEnd and last value of AudioCueEnd_harp\n",
    "trials_df['AudioCueEnd_diff'] = trials_df['AudioCueEnd'] - trials_df['AudioCueEnd_harp'].apply(lambda x: x[-1])\n",
    "\n",
    "# Plot histogram of differences between AudioCueEnd in harp binary file versus AudioCueEnd in .csv\n",
    "trials_df['AudioCueEnd_diff'].hist(bins=100, ax=axs[1])\n",
    "axs[1].set_title('Difference between AudioCueEnd\\nand last value of AudioCueEnd_harp')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TrialStart from experimental-data.csv as the trial start introduces anomalies in the Audio Cue Start/End times within the trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_sounds(trial_start_times, sound_reader, bin_sound_path, OFF_index=18):\n",
    "    # Read the harp sound card stream, for the timestamps and audio ID\n",
    "    all_sounds = hu.get_all_sounds(sound_reader, bin_sound_path)\n",
    "\n",
    "    # Create lists to store the poke IDs and timestamps for all trials\n",
    "    ON_S, OFF_S, ID_S = [], [], []\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < len(trial_start_times) - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = all_sounds[(all_sounds.Time >= start_time) & (all_sounds.Time <= end_time)]\n",
    "\n",
    "        # Create trial lists for sounds this trial\n",
    "        ON, OFF, ID = [], [], []\n",
    "        for _, sound in trial_events.iterrows():\n",
    "            event_time = sound.Time\n",
    "            sound = sound[['PlaySoundOrFrequency']]\n",
    "            sound = int(sound.iloc[0])\n",
    "\n",
    "            # Find audio IDs from the value. Only find ID for OFFSET\n",
    "            if sound != OFF_index:\n",
    "                ON.append(event_time)\n",
    "                ID.append(sound)\n",
    "            else:\n",
    "                OFF.append(event_time)\n",
    "\n",
    "        ON_S.append(ON)\n",
    "        OFF_S.append(OFF)\n",
    "        ID_S.append(ID)\n",
    "        \n",
    "    trial_sounds_df = pd.DataFrame({'AudioCueStart_harp': ON_S, 'AudioCueEnd_harp': OFF_S, 'AudioCueIdentity_harp': ID_S})  # Create dataframe from all nosepoke events\n",
    "\n",
    "    return trial_sounds_df\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial from Trial Start inferred from harp TTLs\n",
    "trial_sounds_df_TrialStart_harp = parse_trial_sounds(trials_df['TrialStart_harp'], sound_reader, bin_sound_path)\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial from Trial Start taken from experimental-data.csv\n",
    "trial_sounds_df_TrialStart = parse_trial_sounds(trials_df['TrialStart'], sound_reader, bin_sound_path)\n",
    "\n",
    "# Check if trial_sounds_df_TrialStart_harp and trial_sounds_df_TrialStart are the same\n",
    "are_identical = trial_sounds_df_TrialStart_harp.equals(trial_sounds_df_TrialStart)\n",
    "print(are_identical)\n",
    "\n",
    "# Pinpoint specific trials where the sound dataframes differ\n",
    "diff = trial_sounds_df_TrialStart_harp != trial_sounds_df_TrialStart\n",
    "diff_idx = diff.any(axis=1)\n",
    "print(trial_sounds_df_TrialStart_harp[diff_idx])\n",
    "print(trial_sounds_df_TrialStart[diff_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that TrialStart from experimental-data.csv always precedes TrialStart_harp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(trials_df['TrialStart_harp'] < trials_df['TrialStart']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timestamps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
