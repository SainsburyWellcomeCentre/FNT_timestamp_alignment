{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get harp TTL data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries and define data folder\n",
    "import harp\n",
    "import pandas as pd\n",
    "from harp.model import Model, Register, Access\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.harp_utils as hu\n",
    "\n",
    "#==============================================================================\n",
    "animal_ID = 'FNT099'\n",
    "session_ID = '2024-05-13T11-03-59'\n",
    "# session_ID = '2024-03-13T10-49-40'\n",
    "\n",
    "# animal_ID = 'FNT107'\n",
    "# session_ID = '2024-08-11T14-01-24'\n",
    "\n",
    "# path behavioural data on ceph repo\n",
    "input_dir = Path(\"W:/projects/FlexiVexi/raw_data\")\n",
    "output_dir = Path(\"C:/Users/megan/Documents/sjlab/flexible-navigation-task\" +\n",
    "              r\"/data_analysis/intermediate_variables\")\n",
    "\n",
    "#==============================================================================\n",
    "\n",
    "# Create reader for behavior.\n",
    "bin_b_path = input_dir / animal_ID / session_ID / \"Behavior.harp\"\n",
    "behavior_reader = harp.create_reader(bin_b_path)\n",
    "\n",
    "# Specify mapping from sound index to reward port\n",
    "soundIdx0 = 14\n",
    "soundIdx1 = 10\n",
    "soundOffIdx = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align dot times with experimental-data-csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import behavioral data as data frame\n",
    "session_path = input_dir / animal_ID / session_ID\n",
    "filepath = session_path / 'Experimental-data' / (session_ID + '_experimental-data.csv')\n",
    "trials_df = pd.read_csv(filepath)\n",
    "\n",
    "# Get dot onset and offset times given by TTL pulses\n",
    "\n",
    "## First dot onset time from software clock (used as a common sense check for inconsistencies with number of TTL pulses on start up)\n",
    "t0 = trials_df['DotOnsetTime'].iloc[0]\n",
    "\n",
    "## Get dot times from TTL pulses\n",
    "[dot_times_ttl, ttl_state_0] = hu.get_dot_times_from_ttl(behavior_reader, t0, return_TTL_state_at_startup=True)\n",
    "print('TTL state upon start-up: ', ttl_state_0)\n",
    "\n",
    "# Append dot onset and offset times given by TTL pulses to trials_df\n",
    "trials_df = pd.concat([trials_df, dot_times_ttl],axis=1)\n",
    "\n",
    "# Common sense check that the logic of aligning the TTL pulses is working as expected.\n",
    "# Check dot onset and times from software clock TTL pulses are consistent, given by:\n",
    "# - DotOnsetTime = dot onset time from software clock\n",
    "# - DotOnsetTime_ttl = dot onset time from TTL pulses\n",
    "# - DotOffsetTime = dot offset time from software clock\n",
    "# - DotOffsetTime_ttl = dot offset time from TTL pulses\n",
    "\n",
    "trials_df[['TrialStart', 'DotOnsetTime', 'DotOffsetTime', 'DotOnsetTime_harp_ttl', 'DotOffsetTime_harp_ttl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all poke events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the behavior harp stream, Digital Input states for the nosepoke timestamps and IDs. Drop DI3 <-- What's DI3??\n",
    "all_pokes = behavior_reader.DigitalInputState.read()\n",
    "\n",
    "all_pokes.drop(columns=['DI3','DIPort2'],inplace = True) # remove all nose pokes to dummy port\n",
    "#all_pokes.reset_index(inplace=True)\n",
    "\n",
    "# Show resulting data frame\n",
    "all_pokes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all audio events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the harp sound card stream, for the timestamps and audio ID\n",
    "all_sounds = hu.get_all_sounds(bin_sound_path)\n",
    "\n",
    "# Show dataframe (maybe)\n",
    "all_sounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get trial start times in harp clock**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check training stage specified in 'trials_df'\n",
    "stage = trials_df['TrainingStage'].iloc[0]\n",
    "\n",
    "# get trial start times for the specified stage\n",
    "if stage == 4:\n",
    "    dot_onset_times = trials_df['DotOnsetTime_harp_ttl']\n",
    "    trial_start_times = hu.get_trial_start_times(4, dot_onset_times=dot_onset_times)\n",
    "elif stage == 5:\n",
    "    trial_start_times = hu.get_trial_start_times(5, bin_sound_path=bin_sound_path, sound_reader=sound_reader)\n",
    "\n",
    "# Append trial start times to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_start_times.rename('TrialStart_harp')],axis=1)\n",
    "\n",
    "trials_df[['TrialStart', 'TrialStart_harp', 'DotOnsetTime', 'DotOffsetTime', 'DotOnsetTime_harp_ttl', 'DotOffsetTime_harp_ttl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align poke events with trials**\n",
    "\n",
    "Get data frame with port choice ID and timestamp for each trial, where the port choice is taken as the first nose poke within the response window (between dot offset and trial end). If the trial is aborted, the port ID and timestamp are both taken as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.harp_utils as hu\n",
    "\n",
    "# Get data frame with port choice ID and timestamp for each trial\n",
    "port_choice_df = hu.get_port_choice(trials_df, behavior_reader)\n",
    "\n",
    "# Append port choice to trials_df\n",
    "trials_df = pd.concat([trials_df, port_choice_df],axis=1)\n",
    "\n",
    "# Show port choice data frame\n",
    "port_choice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align sound events to trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_sounds(trial_start_times, bin_sound_path, OFF_index=18):\n",
    "    \n",
    "    # Read the harp sound card stream, for the timestamps and audio ID\n",
    "    all_sounds = hu.get_all_sounds(bin_sound_path)\n",
    "\n",
    "    # Create lists to store the poke IDs and timestamps for all trials\n",
    "    ON_S, OFF_S, ID_S = [], [], []\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < len(trial_start_times) - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = all_sounds[(all_sounds.Time >= start_time) & (all_sounds.Time <= end_time)]\n",
    "\n",
    "        # Create trial lists for sounds this trial\n",
    "        ON, OFF, ID = [], [], []\n",
    "        for _, sound in trial_events.iterrows():\n",
    "            event_time = sound.Time\n",
    "            sound = sound[['PlaySoundOrFrequency']]\n",
    "            sound = int(sound.iloc[0])\n",
    "\n",
    "            # Find audio IDs from the value. Only find ID for OFFSET\n",
    "            if sound != OFF_index:\n",
    "                ON.append(event_time)\n",
    "                ID.append(sound)\n",
    "            else:\n",
    "                OFF.append(event_time)\n",
    "\n",
    "        ON_S.append(ON)\n",
    "        OFF_S.append(OFF)\n",
    "        ID_S.append(ID)\n",
    "        \n",
    "    trial_sounds_df = pd.DataFrame({'AudioCueStart_harp': ON_S, 'AudioCueEnd_harp': OFF_S, 'AudioCueIdentity_harp': ID_S})  # Create dataframe from all nosepoke events\n",
    "\n",
    "    return trial_sounds_df\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial\n",
    "trial_sounds_df = parse_trial_sounds(trials_df['TrialStart'], bin_sound_path)\n",
    "\n",
    "# Append sound ID to trials_df\n",
    "trials_df = pd.concat([trials_df, trial_sounds_df],axis=1)\n",
    "\n",
    "# Show sound data frame\n",
    "trial_sounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check trials_df AudioCueStart and ChoicePort is as expected\n",
    "trials_df[\n",
    "    [\n",
    "        'TrialStart',\n",
    "        'TrialStart_harp',\n",
    "        'TrialCompletionCode',\n",
    "        'ChoicePort',\n",
    "        'ChoiceTimestamp',\n",
    "        'AudioCueStart_harp',\n",
    "        'AudioCueEnd_harp',\n",
    "        'AudioCueIdentity'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistency of harp clock timestamps with experimental-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DotOnsetTime and TrialStart are distinct on stage 4.1 in experimental-data.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take difference between TrialStart and DotOnsetTime_harp\n",
    "test = trials_df['TrialStart'] - trials_df['DotOnsetTime']\n",
    "\n",
    "# Get histogram of differences between DotOnsetTime_harp and DotOnsetTime\n",
    "fig, ax = plt.subplots()\n",
    "test.hist(bins=100, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial start time inferred from TTL pulses has some jitter relative to TrialStart (or DotOnset) in experimental-data.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take difference between TrialStart and DotOnsetTime_harp_ttl\n",
    "trials_df['DotOnsetTime_harp_diff'] = trials_df['DotOnsetTime_harp_ttl'] - trials_df['TrialStart']\n",
    "print(sum(trials_df['DotOnsetTime_harp_diff'] < 0))\n",
    "# Get histogram of differences between DotOnsetTime_harp_ttl and DotOnsetTime\n",
    "fig, ax = plt.subplots()\n",
    "trials_df['DotOnsetTime_harp_diff'].hist(bins=100, ax=ax)\n",
    "ax.set_title('Histogram of differences between DotOnsetTime_harp_ttl and TrialStart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp of nosepoke for port choice is identical in both experimental-data.csv and harp binary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take difference between TrialStart and DotOnsetTime_harp\n",
    "trials_df['choiceTimestamp_diff'] = trials_df['ChoiceTimestamp'] - trials_df['NosepokeInTime']\n",
    "\n",
    "# Get histogram of differences between DotOnsetTime_harp and DotOnsetTime\n",
    "fig, ax = plt.subplots()\n",
    "trials_df['choiceTimestamp_diff'].hist(bins=100, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare sound onset time in experimental-data.csv to sound onset in harp time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df[\n",
    "    [\n",
    "        'AudioCueStart',\n",
    "        'AudioCueStart_harp',\n",
    "        'AudioCueEnd',\n",
    "        'AudioCueEnd_harp',\n",
    "        'AudioCueIdentity'\n",
    "    ]\n",
    "].head()\n",
    "\n",
    "# Check if the number of elements in AudioCueStart_harp matches the number of elements in AudioCueEnd_harp\n",
    "def check_audio_cue_lengths(row):\n",
    "    return len(row['AudioCueStart_harp']) == len(row['AudioCueEnd_harp'])\n",
    "\n",
    "# Apply the function to each row and store the result in a new column\n",
    "trials_df['AudioCueLengthsMatch'] = trials_df.apply(check_audio_cue_lengths, axis=1)\n",
    "\n",
    "# Display the rows where the lengths do not match\n",
    "mismatched_rows = trials_df[~trials_df['AudioCueLengthsMatch']]\n",
    "print(mismatched_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioCueStart in experimental-data.csv matches the final instance of Audio Cue Onset from harp binaries within the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Get difference between AudioCueStart and first value of AudioCueStart_harp\n",
    "trials_df['AudioCueStart_diff'] = trials_df['AudioCueStart'] - trials_df['AudioCueStart_harp'].apply(lambda x: x[0])\n",
    "\n",
    "# Plot histogram of differences between AudioCueStart in harp binary file versus AudioCueStart in .csv\n",
    "trials_df['AudioCueStart_diff'].hist(bins=100, ax=axs[0])\n",
    "axs[0].set_title('Difference between AudioCueStart\\nand first value of AudioCueStart_harp')\n",
    "\n",
    "# Get difference between AudioCueStart and last value of AudioCueStart_harp\n",
    "trials_df['AudioCueStart_diff'] = trials_df['AudioCueStart'] - trials_df['AudioCueStart_harp'].apply(lambda x: x[-1])\n",
    "\n",
    "# Plot histogram of differences between AudioCueStart in harp binary file versus AudioCueStart in .csv\n",
    "trials_df['AudioCueStart_diff'].hist(bins=100, ax=axs[1])\n",
    "axs[1].set_title('Difference between AudioCueStart\\nand last value of AudioCueStart_harp')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioCueEnd from experimental-data.csv deviates significantly from first or last Audio Cue End from harp binaries in many trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Get difference between AudioCueEnd and first value of AudioCueEnd_harp\n",
    "trials_df['AudioCueEnd_diff'] = trials_df['AudioCueEnd'] - trials_df['AudioCueEnd_harp'].apply(lambda x: x[0])\n",
    "\n",
    "# Plot histogram of differences between AudioCueEnd in harp binary file versus AudioCueEnd in .csv\n",
    "trials_df['AudioCueEnd_diff'].hist(bins=100, ax=axs[0])\n",
    "axs[0].set_title('Difference between AudioCueEnd\\nand first value of AudioCueEnd_harp')\n",
    "\n",
    "# Get difference between AudioCueEnd and last value of AudioCueEnd_harp\n",
    "trials_df['AudioCueEnd_diff'] = trials_df['AudioCueEnd'] - trials_df['AudioCueEnd_harp'].apply(lambda x: x[-1])\n",
    "\n",
    "# Plot histogram of differences between AudioCueEnd in harp binary file versus AudioCueEnd in .csv\n",
    "trials_df['AudioCueEnd_diff'].hist(bins=100, ax=axs[1])\n",
    "axs[1].set_title('Difference between AudioCueEnd\\nand last value of AudioCueEnd_harp')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df\n",
    "# Print all unique values in the 'TrialCompletionCode' column\n",
    "unique_values = trials_df['TrialCompletionCode'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "print(trials_df['TrainingStage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trials_df to include only rows where 'TrialCompletionCode' is 'AbortedTrial-1'\n",
    "aborted_trials = trials_df[trials_df['TrialCompletionCode'] == 'AbortedTrial-1']\n",
    "print(len(aborted_trials))\n",
    "\n",
    "# Show the 'AudioCueEnd_diff' column for these filtered rows\n",
    "audio_cue_end_diff_aborted = aborted_trials['AudioCueEnd_diff']\n",
    "print(audio_cue_end_diff_aborted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that every value in 'AudioCueEnd' occurs between 'TrialStart' for that row and the 'TrialStart' from the subsequent row\n",
    "def check_audio_cue_end(trials_df):\n",
    "    for i in range(len(trials_df) - 1):\n",
    "        start_time = trials_df.loc[i, 'TrialStart']\n",
    "        end_time = trials_df.loc[i + 1, 'TrialStart']\n",
    "        audio_cue_end = trials_df.loc[i, 'AudioCueEnd']\n",
    "        \n",
    "        if not (start_time <= audio_cue_end < end_time):\n",
    "            print(f\"AudioCueEnd at index {i} is out of bounds: {audio_cue_end}\")\n",
    "            return False\n",
    "    \n",
    "    # Check the last row separately as it doesn't have a subsequent row\n",
    "    last_start_time = trials_df.iloc[-1]['TrialStart']\n",
    "    last_audio_cue_end = trials_df.iloc[-1]['AudioCueEnd']\n",
    "    \n",
    "    if last_audio_cue_end < last_start_time:\n",
    "        print(f\"AudioCueEnd at the last index is out of bounds: {last_audio_cue_end}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "is_valid = check_audio_cue_end(trials_df)\n",
    "print(f\"All AudioCueEnd values are within bounds: {is_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot all instances of AudioCueStart, AudioCueEnd, and TrialStart in the same plot\n",
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "\n",
    "# Plot AudioCueStart\n",
    "ax.plot(trials_df['AudioCueStart'], [1] * len(trials_df), 'go', label='AudioCueStart')\n",
    "\n",
    "# Plot AudioCueEnd\n",
    "ax.plot(trials_df['AudioCueEnd'], [2] * len(trials_df), 'ro', label='AudioCueEnd')\n",
    "\n",
    "# Plot TrialStart\n",
    "ax.vlines(trials_df['TrialStart'], [3] * len(trials_df), 'bo', label='TrialStart')\n",
    "\n",
    "# Set y-ticks to show labels\n",
    "ax.set_yticks([1, 2, 3])\n",
    "ax.set_yticklabels(['AudioCueStart', 'AudioCueEnd', 'TrialStart'])\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_title('Timestamps of AudioCueStart, AudioCueEnd, and TrialStart')\n",
    "ax.set_xlim(trials_df['TrialStart'].min(), trials_df['TrialStart'].min()+150)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "df = trials_df[['AudioCueStart','AudioCueEnd', 'AudioCueStart_harp', 'AudioCueEnd_harp']]\n",
    "\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TrialStart from experimental-data.csv as the trial start introduces anomalies in the Audio Cue Start/End times within the trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trial_sounds(trial_start_times, bin_sound_path, OFF_index=18):\n",
    "    # Read the harp sound card stream, for the timestamps and audio ID\n",
    "    all_sounds = hu.get_all_sounds(bin_sound_path)\n",
    "\n",
    "    # Create lists to store the poke IDs and timestamps for all trials\n",
    "    ON_S, OFF_S, ID_S = [], [], []\n",
    "\n",
    "    # Iterate through trial start times and extract data from harp stream\n",
    "    for i, start_time in enumerate(trial_start_times):\n",
    "        if i < len(trial_start_times) - 1:\n",
    "            end_time = trial_start_times[i + 1]\n",
    "        else:\n",
    "            end_time = start_time + 100  # 100 seconds after the last trial start time\n",
    "\n",
    "        # Extract events that occur within the time range of this trial\n",
    "        trial_events = all_sounds[(all_sounds.Time >= start_time) & (all_sounds.Time <= end_time)]\n",
    "\n",
    "        # Create trial lists for sounds this trial\n",
    "        ON, OFF, ID = [], [], []\n",
    "        for _, sound in trial_events.iterrows():\n",
    "            event_time = sound.Time\n",
    "            sound = sound[['PlaySoundOrFrequency']]\n",
    "            sound = int(sound.iloc[0])\n",
    "\n",
    "            # Find audio IDs from the value. Only find ID for OFFSET\n",
    "            if sound != OFF_index:\n",
    "                ON.append(event_time)\n",
    "                ID.append(sound)\n",
    "            else:\n",
    "                OFF.append(event_time)\n",
    "\n",
    "        ON_S.append(ON)\n",
    "        OFF_S.append(OFF)\n",
    "        ID_S.append(ID)\n",
    "        \n",
    "    trial_sounds_df = pd.DataFrame({'AudioCueStart_harp': ON_S, 'AudioCueEnd_harp': OFF_S, 'AudioCueIdentity_harp': ID_S})  # Create dataframe from all nosepoke events\n",
    "\n",
    "    return trial_sounds_df\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial from Trial Start inferred from harp TTLs\n",
    "trial_sounds_df_TrialStart_harp = parse_trial_sounds(trials_df['TrialStart_harp'], bin_sound_path)\n",
    "\n",
    "# Get data frame with sound ID and timestamp for each trial from Trial Start taken from experimental-data.csv\n",
    "trial_sounds_df_TrialStart = parse_trial_sounds(trials_df['TrialStart'], bin_sound_path)\n",
    "\n",
    "# Check if trial_sounds_df_TrialStart_harp and trial_sounds_df_TrialStart are the same\n",
    "are_identical = trial_sounds_df_TrialStart_harp.equals(trial_sounds_df_TrialStart)\n",
    "print(are_identical)\n",
    "\n",
    "# Pinpoint specific trials where the sound dataframes differ\n",
    "diff = trial_sounds_df_TrialStart_harp != trial_sounds_df_TrialStart\n",
    "diff_idx = diff.any(axis=1)\n",
    "print(trial_sounds_df_TrialStart_harp[diff_idx])\n",
    "print(trial_sounds_df_TrialStart[diff_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that TrialStart from experimental-data.csv always precedes TrialStart_harp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(trials_df['TrialStart_harp'] < trials_df['TrialStart']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timestamps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
